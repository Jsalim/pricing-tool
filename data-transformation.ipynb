{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'c:/data/mrh/axaf_mrh_tot_freq_tot.csv'\n",
    "features = [\n",
    "    'ddea_quant_cm_10',\n",
    "    'HAB_nb_pieces',\n",
    "    'HAB_qual',\n",
    "    'HAB_anclg',\n",
    "    'CLI_age',\n",
    "    #'POL_mtcapass',\n",
    "    'HAB_habit',\n",
    "    'CLI_sex',\n",
    "    #'POL_tr_tx_objv',\n",
    "    'POL_fract',\n",
    "    'annee',\n",
    "    'CLI_nb_enfant',\n",
    "]\n",
    "exposure = 'anpol'\n",
    "targets = ['nbsinDDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_csv_separator(filename):\n",
    "    \"\"\"Utility function to automatically detect the separator character in a csv file.\"\"\"\n",
    "    with open(filename) as csvfile:\n",
    "        first_line = csvfile.readline()\n",
    "        return csv.Sniffer().sniff(first_line).delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_file(out_filename, dtype, shape):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        out_filename: The name of the binary file. It must be in the same\n",
    "            directory.\n",
    "        dtype: The type of the numpy array.\n",
    "    \"\"\"\n",
    "    out_file = open(out_filename, 'wb+')\n",
    "    dat_file = np.memmap(out_file, dtype=dtype, shape=shape)\n",
    "    return dat_file\n",
    "\n",
    "        \n",
    "def save_data_file(file, filename):\n",
    "    file.flush()\n",
    "    size = float(file.nbytes) / (1024 ** 2)\n",
    "    print('written %s : %.3f MB' % (filename, size))\n",
    "\n",
    "    \n",
    "def create_data_file_from_list(lst, out_filename, dtype):\n",
    "    \"\"\"Write a list in a binary file as a numpy array.\n",
    "    Args:\n",
    "        lst: The list that will be written in the file.\n",
    "        out_filename: The name of the binary file. It must be in the same\n",
    "            directory.\n",
    "        dtype: The type of the numpy array.\n",
    "    \"\"\"\n",
    "    with open(out_filename, 'wb+') as out_file:\n",
    "        dat_file = np.memmap(out_file, dtype=dtype, shape=(len(lst),))\n",
    "        dat_file[:] = lst[:]\n",
    "        dat_file.flush()\n",
    "    size = float(dat_file.nbytes) / (1024 ** 2)\n",
    "    print('written %s : %.3f MB' % (out_filename, size))\n",
    "\n",
    "def load_data(file_path, dtype='int32', shape=None):\n",
    "    return np.memmap(file_path, dtype=dtype, shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import (takewhile,repeat)\n",
    "\n",
    "def count_line(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum(buf.count(b'\\n') for buf in bufgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0\n",
    "\n",
    "# Print iterations progress\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    global start_time\n",
    "    if iteration == 0:\n",
    "        start_time = time.time()\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    m = str(elapsed_time // 60).zfill(2)\n",
    "    s = str(elapsed_time % 60).zfill(2)\n",
    "    print('\\r%s |%s| %s%% %s in %sm%ss' % (prefix, bar, percent, suffix, m, s), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(csv_filename, data_filename, features, targets, exposure):\n",
    "    print('Starting data importation.')\n",
    "    sep = detect_csv_separator(csv_filename)\n",
    "    nb_lines = count_line(filename)\n",
    "    print(\"Importing\", '{:,}'.format(nb_lines).replace(',', ' '), \"lines.\")\n",
    "    nb_features = len(features)\n",
    "    observations = create_data_file(data_filename, np.dtype('u1'), (nb_lines, nb_features))\n",
    "    exposure_data = create_data_file('./data/exposure.dat', np.dtype('float32'), (nb_lines))\n",
    "    targets_data = create_data_file('./data/targets.dat', np.dtype('float32'), (nb_lines, len(targets)))\n",
    "    with open(csv_filename) as csv_file:\n",
    "        fields = [s.strip() for s in csv_file.readline().split(sep)]\n",
    "        nb_fields = len(fields)\n",
    "        features_index = [i for i in range(nb_fields) if fields[i] in features]\n",
    "        if len(features_index) != nb_features:\n",
    "            raise Exception(\"Invalid features\")\n",
    "        features_mapping = [{} for i in range(nb_features)]\n",
    "        exposure_index = [i for i in range(nb_fields) if fields[i] == exposure]\n",
    "        if len(exposure_index) != 1:\n",
    "            raise Exception(\"Invalid Exposure field.\")\n",
    "        exposure_index = exposure_index[0]\n",
    "        targets_index = [i for i in range(nb_fields) if fields[i] in targets]\n",
    "        if len(targets_index) != len(targets):\n",
    "            raise Exception(\"Invalid targets\")\n",
    "            \n",
    "        for i, line in enumerate(csv_file):\n",
    "            values = line.split(sep)\n",
    "            if len(values) != nb_fields:\n",
    "                raise Exception(\"Inconsistent number of fields\", len(values),  \"in line\", i + 1, \"expecting\", len(fields))\n",
    "            for j, index in enumerate(features_index):\n",
    "                v = values[index]\n",
    "                a = features_mapping[j].setdefault(v, len(features_mapping[j]))\n",
    "                if a > 200:\n",
    "                    raise Exception(\"Feature\", fields[j], \"has too many modalities ( more than 200).\")\n",
    "                observations[i, j] = a\n",
    "            targets_data[i, :] = [values[index] for index in targets_index]\n",
    "            exposure_data[i] = values[exposure_index]\n",
    "            if i % 1000 == 0 or i == nb_lines - 2:\n",
    "                printProgressBar(i, nb_lines - 2, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    save_data_file(observations, csv_filename)\n",
    "    save_data_file(targets_data, './data/exposure.dat')\n",
    "    save_data_file(exposure_data, './data/targets.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data importation.\n",
      "Importing 8 420 946 lines.\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete in 04m17s\n",
      "written c:/data/mrh/axaf_mrh_tot_freq_tot.csv : 80.308 MB\n",
      "written ./data/exposure.dat : 32.123 MB\n",
      "written ./data/targets.dat : 32.123 MB\n"
     ]
    }
   ],
   "source": [
    "transform(filename, './data/observations.dat', features, [target], exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.memmap('./data/observations.dat', np.dtype('u1'))\n",
    "exposure_data = np.memmap('./data/exposure.dat', np.dtype('float32'))\n",
    "targets_data = np.memmap('./data/targets.dat', np.dtype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "1 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "2 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "3 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "4 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "5 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "6 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "7 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "8 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "9 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "10 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "11 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "12 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "13 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "14 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "15 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "16 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "17 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "18 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "19 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "20 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "21 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "22 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "23 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "24 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "25 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "26 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "27 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "28 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "29 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "30 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "31 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "32 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "33 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "34 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "35 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "36 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "37 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "38 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "39 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "40 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "41 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "42 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "43 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "44 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "45 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "46 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "47 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "48 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "49 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "50 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "51 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "52 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "53 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "54 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "55 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "56 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "57 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "58 b'\\x00\\x00\\x80?' 1.0 1.0\n",
      "59 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "60 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "61 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "62 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "63 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "64 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "65 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "66 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "67 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "68 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "69 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "70 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "71 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "72 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "73 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "74 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "75 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "76 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "77 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "78 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "79 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "80 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "81 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "82 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "83 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "84 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "85 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "86 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "87 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "88 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "89 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "90 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "91 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "92 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "93 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "94 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "95 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "96 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "97 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "98 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n",
      "99 b'\\x00\\x00\\x00\\x00' 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import struct\n",
    "\n",
    "with open('./data/targets.dat', 'rb') as tf:\n",
    "    for i in range(100):\n",
    "        b = tf.read(4)\n",
    "        # int.from_bytes(b, sys.byteorder)\n",
    "        print(i, b, struct.unpack('f', b)[0] , targets_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
